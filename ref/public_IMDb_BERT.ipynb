{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "public-IMDb-BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sciencecw/AI4Code/blob/BERT/ref/public_IMDb_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrEj5SI6MITG"
      },
      "source": [
        "# Sentiment Analysis of IMDb Movie Reviews Using BERT\n",
        "\n",
        "In this notebook, we build a binary text classifier to classify movie reviews as either positive or negative using [BERT](https://arxiv.org/abs/1810.04805), a pretrained NLP model that can be used for transfer learning on text data.  We will use the [*ktrain* library](https://github.com/amaiya/ktrain), a lightweight wrapper around Keras to help train (and deploy) neural networks.  For more information on *ktrain*, see [this Medium post](https://towardsdatascience.com/ktrain-a-lightweight-wrapper-for-keras-to-help-train-neural-networks-82851ba889c).\n",
        "\n",
        "We will begin by installing *ktrain* and importing the required *ktrain* modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijx0A5xdKb0W"
      },
      "source": [
        "# install ktrain\n",
        "!pip3 install ktrain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcIYcnNz-NJU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP1NQGtsQaSW",
        "outputId": "46e3440a-5dd9-4383-d082-3af6fd89f1da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import ktrain\n",
        "import ktrain\n",
        "from ktrain import text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6ek6R2JQkdt",
        "outputId": "4d912ed9-92c9-40b8-d371-472985eb91f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ktrain.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.2.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjhNBvJFKxsI"
      },
      "source": [
        "Next, we will fetch and extract the IMDb movie review dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5lJ5jXpqtM9",
        "outputId": "8b453a2b-35b0-43b1-e80d-6de284218057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# download IMDb movie review dataset\n",
        "import tensorflow as tf\n",
        "dataset = tf.keras.utils.get_file(\n",
        "    fname=\"aclImdb.tar.gz\", \n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "    extract=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsyxR4znrGi6",
        "outputId": "dddb4451-e8d4-4b55-dfc1-4acc03b85e7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# set path to dataset\n",
        "import os.path\n",
        "#dataset = '/root/.keras/datasets/aclImdb'\n",
        "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "print(IMDB_DATADIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.keras/datasets/aclImdb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Nm5-uiiMj0I"
      },
      "source": [
        "## STEP 1:  Load and Preprocess the Dataset\n",
        "\n",
        "The `texts_from_folder` function will load the training and validation data from the specified folder and automatically preprocess it according to BERT's requirements.  In doing so, the BERT model and vocabulary will be automatically downloaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFk_JVfisLbm",
        "outputId": "9559b505-7792-4832-b0f7-07e341bb6738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "trn, val, preproc = text.texts_from_folder(IMDB_DATADIR, \n",
        "                                          maxlen=500, \n",
        "                                          preprocess_mode='bert',\n",
        "                                          train_test_names=['train', \n",
        "                                                            'test'],\n",
        "                                          classes=['pos', 'neg'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading pretrained BERT model and vocabulary...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model and vocabulary...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "preprocessing test...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Eh8CLd0Mpd5"
      },
      "source": [
        "## STEP 2:  Load a pretrained BERT model and wrap it in a `ktrain.Learner` object\n",
        "\n",
        "This step can be condensed into a single line of code, but we execute it as two lines for clarity. (You can ignore the deprecation warnings arising from Keras 2.2.4 with TensorFlow 1.14.0.)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVCCpjtKwfTs",
        "outputId": "26d5fede-1d0d-47b1-8b71-59cbe987569a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "model = text.text_classifier('bert', trn, preproc=preproc)\n",
        "learner = ktrain.get_learner(model,train_data=trn, val_data=val, batch_size=6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0817 15:50:35.441357 140312423020416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0817 15:50:35.481600 140312423020416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0817 15:50:35.535026 140312423020416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0817 15:50:35.535914 140312423020416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0817 15:50:35.546988 140312423020416 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0817 15:50:35.577237 140312423020416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0817 15:50:55.827762 140312423020416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g9dwBJqNgvR"
      },
      "source": [
        "## STEP 3:  Train and Fine-Tune the Model on the IMDb dataset\n",
        "\n",
        "We employ the `learner.fit_onecycle` method in *ktrain* that employs the use of a [1cycle learning  rate schedule](https://arxiv.org/pdf/1803.09820.pdf).  We use a learning rate of 2e-5 based on recommendations from [the original paper](https://arxiv.org/abs/1810.04805).\n",
        "\n",
        "As can be seen, we achieve a **93.92% validation accuracy** in a single epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhHGCuPhv5Ew",
        "outputId": "dc9984d3-ee6c-4555-d5b2-0df5833a801b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "learner.fit_onecycle(2e-5, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0817 15:50:59.892966 140312423020416 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/1\n",
            "25000/25000 [==============================] - 4591s 184ms/step - loss: 0.2524 - acc: 0.8960 - val_loss: 0.1601 - val_acc: 0.9392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9cb4d02da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBE749i3QaMu"
      },
      "source": [
        "Since it does not appear we are overfitting yet, we could train for an additional epoch or two for even higher accuracy.  \n",
        "\n",
        "Feel free to try it out on your own."
      ]
    }
  ]
}