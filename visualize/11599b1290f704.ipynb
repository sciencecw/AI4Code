{"cells": [{"cell_type": "markdown", "id": "d0c71c31", "metadata": {}, "source": ["# Look at the low variance features - are they useless?\n\nAs pointed out by Chris Deotte, the features for each value of wheezy-copper-turtle-magic have either a 'high' or 'low' variance. Chris suggested that the low variance features were not useful predictors of the target.\n\nAnother [kernel](https://www.kaggle.com/mhviraf/there-is-predictive-power-in-the-useless-columns) also questioned if they were useful. \n\nChris also [demonstrated](https://www.kaggle.com/c/instant-gratification/discussion/93379) the curse of dimensionality, and how it can lead to seperability, even for random noise.\n\nI wanted to do a quick check of if the low-variance features were indeed useless. I thought I might as well share the kernel. I just fitted a quick NuSVC using three different feature selection methods.\n\n\n**Summary:** Assuming the features are independent, it does not appear the low-variance features contain any useful predictors of the target. This agrees with all previous work."]}, {"cell_type": "code", "execution_count": 1, "id": "74de9615", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.feature_selection import mutual_info_classif, VarianceThreshold\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import NuSVC\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_auc_score\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output."]}, {"cell_type": "code", "execution_count": 1, "id": "699c2767", "metadata": {}, "outputs": [], "source": ["def get_data(target_name='target'):\n    \"\"\"\n    Gets the training data and extracts the target. \n    \n    Returns:\n        train (pd.DataFrame): training data.\n        target (np.ndarray): target values, binary\n    \"\"\"\n    train = pd.read_csv(\"../input/train.csv\")\n    test = pd.read_csv(\"../input/test.csv\")\n    try:\n        target = train[target_name]\n        train.drop(target_name, axis=1, inplace=True)\n    except KeyError:\n        # no column named target_name, find binary column\n        for key in train.columns:\n            x = train[key].values\n            if np.array_equal(x, x.astype(bool)):\n                target_name = key\n        target = train[target_name]\n        train.drop(target_name, axis=1, inplace=True)\n    print('The column used as target is : {}'.format(target_name))\n    return train, test, target"]}, {"cell_type": "code", "execution_count": 1, "id": "e1b7bf6c", "metadata": {}, "outputs": [], "source": ["train, test, target = get_data()"]}, {"cell_type": "code", "execution_count": 1, "id": "927ca518", "metadata": {}, "outputs": [], "source": ["wheezy_value = 65\n\ntrain_wheezy = train.loc[train['wheezy-copper-turtle-magic']==wheezy_value,:]\ntarget_wheezy = target[train_wheezy.index].values\ntrain_wheezy.drop(['id', 'wheezy-copper-turtle-magic'], inplace=True, axis=1)"]}, {"cell_type": "markdown", "id": "f7b3cdd2", "metadata": {}, "source": ["### Mutual information\n\nSome of the 'low variance features' have a relatively high mutual information. So it is worth investigating further if they contain any predictive power.\n\nI don't understand why the Mutual information does not appear to be a useful measure of feature importance in this case."]}, {"cell_type": "code", "execution_count": 1, "id": "8e6f6396", "metadata": {}, "outputs": [], "source": ["mi = mutual_info_classif(train_wheezy.values, target_wheezy, discrete_features=False)\n\nfeature_stds = train_wheezy.std().values\n\nplt.plot(mi[feature_stds>1.5], label='high variance features')\nplt.plot(mi[feature_stds<1.5], label='low variance features')\nplt.legend()"]}, {"cell_type": "markdown", "id": "9a7ce740", "metadata": {}, "source": ["## Fit a basic model using different feature sets"]}, {"cell_type": "markdown", "id": "aef0dca9", "metadata": {}, "source": ["#### Using the method suggested by Chris as a baseline:\n- Removing the low variance features"]}, {"cell_type": "code", "execution_count": 1, "id": "93f21ad3", "metadata": {}, "outputs": [], "source": ["# select high variance features\ntrain_wheezy_reduced = VarianceThreshold(1.5).fit_transform(train_wheezy)\n\n\nval_scores = np.array([])\ntest_scores = np.array([])\nSS = ShuffleSplit(n_splits=11, test_size=.15, random_state=0)\nfor train_index, test_index in SS.split(train_wheezy_reduced):\n    clf = NuSVC(kernel='poly', degree=4, random_state=4, \n                probability=True, coef0=0.08, gamma='auto')\n    clf.fit(train_wheezy_reduced[train_index,:], target_wheezy[train_index])\n    \n    val_preds = clf.predict_proba(train_wheezy_reduced[test_index,:])\n    train_preds = clf.predict_proba(train_wheezy_reduced[train_index,:])\n    \n    val_score = roc_auc_score(target_wheezy[test_index], val_preds[:,1])\n    train_score = roc_auc_score(target_wheezy[train_index], train_preds[:,1])\n    \n    val_scores = np.append(val_scores, val_score)\n    train_scores = np.append(val_scores, train_score)"]}, {"cell_type": "code", "execution_count": 1, "id": "1c616868", "metadata": {}, "outputs": [], "source": ["print('Validation: {0:.3f} +/- {1:.3f}'.format(np.mean(val_scores), np.std(val_scores)))\nprint('Train: {0:.3f} +/- {1:.3f}'.format(np.mean(train_scores), np.std(train_scores)))"]}, {"cell_type": "markdown", "id": "b4d13f60", "metadata": {}, "source": ["#### Using low-variance features\n\nNow we will test using the low variance features."]}, {"cell_type": "code", "execution_count": 1, "id": "566f91f3", "metadata": {}, "outputs": [], "source": ["# select low variance features\nVT =  VarianceThreshold(1.5)\ntrain_wheezy_reduced = VT.fit_transform(train_wheezy)\ncolumns = train_wheezy.columns.values[VT.variances_<1.5]\ntrain_wheezy_reduced = train_wheezy[columns].values\n\n\nval_scores = np.array([])\ntest_scores = np.array([])\nSS = ShuffleSplit(n_splits=11, test_size=.15, random_state=0)\nfor train_index, test_index in SS.split(train_wheezy_reduced):\n    clf = NuSVC(kernel='poly', degree=4, random_state=4, \n                probability=True, coef0=0.08, gamma='auto')\n    clf.fit(train_wheezy_reduced[train_index,:], target_wheezy[train_index])\n    \n    val_preds = clf.predict_proba(train_wheezy_reduced[test_index,:])\n    train_preds = clf.predict_proba(train_wheezy_reduced[train_index,:])\n    \n    val_score = roc_auc_score(target_wheezy[test_index], val_preds[:,1])\n    train_score = roc_auc_score(target_wheezy[train_index], train_preds[:,1])\n    \n    val_scores = np.append(val_scores, val_score)\n    train_scores = np.append(val_scores, train_score)"]}, {"cell_type": "code", "execution_count": 1, "id": "6d0c6934", "metadata": {}, "outputs": [], "source": ["print('Validation: {0:.3f} +/- {1:.3f}'.format(np.mean(val_scores),np.std(val_scores)))\nprint('Train: {0:.3f} +/- {1:.3f}'.format(np.mean(train_scores),np.std(train_scores)))"]}, {"cell_type": "markdown", "id": "badfe219", "metadata": {}, "source": ["#### Using mutual information\n\nWe will remove features with a low mutual information."]}, {"cell_type": "code", "execution_count": 1, "id": "93d9910e", "metadata": {}, "outputs": [], "source": ["# select low variance features\nmi = mutual_info_classif(train_wheezy.values, target_wheezy)\ncolumns = train_wheezy.columns.values[mi>0.0475]\ntrain_wheezy_reduced = train_wheezy[columns].values\n\n\nval_scores = np.array([])\ntest_scores = np.array([])\n\nSS = ShuffleSplit(n_splits=11, test_size=.15, random_state=0)\nfor train_index, test_index in SS.split(train_wheezy_reduced):\n    clf = NuSVC(kernel='poly', degree=4, random_state=4, \n                probability=True, coef0=0.08, gamma='auto')\n    clf.fit(train_wheezy_reduced[train_index,:], target_wheezy[train_index])\n    \n    val_preds = clf.predict_proba(train_wheezy_reduced[test_index,:])\n    train_preds = clf.predict_proba(train_wheezy_reduced[train_index,:])\n    \n    val_score = roc_auc_score(target_wheezy[test_index], val_preds[:,1])\n    train_score = roc_auc_score(target_wheezy[train_index], train_preds[:,1])\n    \n    val_scores = np.append(val_scores, val_score)\n    train_scores = np.append(val_scores, train_score)"]}, {"cell_type": "code", "execution_count": 1, "id": "ca0a81c4", "metadata": {}, "outputs": [], "source": ["print('Validation: {0:.3f} +/- {1:.3f}'.format(np.mean(val_scores),np.std(val_scores)))\nprint('Train: {0:.3f} +/- {1:.3f}'.format(np.mean(train_scores),np.std(train_scores)))"]}, {"cell_type": "markdown", "id": "266e4190", "metadata": {}, "source": ["#### Is there any 'talk' between the low and high variance features.\n\nAnother thing to check is if there is any interaction between the low and high variance features. \n\nWe can use a pairplot to begin to look into this. \n\n\nThis quick plot doesn't indicate any strong interactions."]}, {"cell_type": "code", "execution_count": 1, "id": "4fe8bd9a", "metadata": {}, "outputs": [], "source": ["high_variance_features = train_wheezy.columns.values[VT.variances_>1.5][9:12]\nlow_variance_features = train_wheezy.columns.values[VT.variances_<1.5][:3]\n\nfeatures_to_plot = np.append(high_variance_features, low_variance_features)\n\nsns.pairplot(train_wheezy[features_to_plot])"]}, {"cell_type": "markdown", "id": "b05c9388", "metadata": {}, "source": ["# Conclusions\n\nLooking at the three models we have constructed it does seem to strongly support the hypothesis that the low variance features hold no predictive power. \n\nIt seems, therefore, that a variance based thresholding is an essential first feature selection step.\n\n\nQuestions to answer:\n - Could they hold information in a way I am not sensitive to in this kernel? I.e., could you have features which appear random, but are not lineraly independent and when combined contain predictors of the target?"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}