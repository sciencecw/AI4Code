{"cells": [{"cell_type": "code", "execution_count": 1, "id": "0bee65a5", "metadata": {}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}, {"cell_type": "markdown", "id": "5ba7a58e", "metadata": {}, "source": ["# Load data"]}, {"cell_type": "code", "execution_count": 1, "id": "c6d1fa70", "metadata": {}, "outputs": [], "source": ["train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\nsample_submission_data = pd.read_csv(\"/kaggle/input/titanic/gender_submission.csv\")"]}, {"cell_type": "code", "execution_count": 1, "id": "4ebf1324", "metadata": {}, "outputs": [], "source": ["train_data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "d336b43d", "metadata": {}, "outputs": [], "source": ["# an initial decription before cleaning and exploratory data analysis\ntrain_data.describe()"]}, {"cell_type": "markdown", "id": "f69f0b5f", "metadata": {}, "source": ["It is strange that the minimum value for fare is zero. Let's look for nans first then take care of it."]}, {"cell_type": "code", "execution_count": 1, "id": "7c9c48fb", "metadata": {}, "outputs": [], "source": ["#null data at a glance\ntrain_data.info()\n# just double checking\ntrain_data.isna().sum()"]}, {"cell_type": "markdown", "id": "93d484ae", "metadata": {}, "source": ["We have null data for the age, cabin, and embarked columns."]}, {"cell_type": "code", "execution_count": 1, "id": "52de6d44", "metadata": {}, "outputs": [], "source": ["# maybe the 0 for the fares is because some of them of are babies? let's check\nfare_mask = train_data['Fare']<5\nfree_loaders = train_data[fare_mask]\nprint(free_loaders[['Age','Fare']])"]}, {"cell_type": "markdown", "id": "547da16e", "metadata": {}, "source": ["So some people are just not paying. Let's not worry about them."]}, {"cell_type": "code", "execution_count": 1, "id": "cff2c001", "metadata": {}, "outputs": [], "source": ["# ask ta for help\n# ignore for now\n# train_data.Fare = train_data.Fare.map(lambda x: np.nan if x==0 else x)\n# classmeans = train_data.pivot_table('Fare', index='Pclass', aggfunc='mean')\n# print(classmeans)\n# train_data.Fare = train_data[['Fare', 'Pclass']].apply(lambda x: classmeans[x['Pclass']] if pd.isna(x['Fare']) else x['Fare'], axis=0 )\n# print(free_loaders[['Age','Fare']])"]}, {"cell_type": "code", "execution_count": 1, "id": "df839874", "metadata": {}, "outputs": [], "source": ["# replace nan ages with mean age\nmeanAge=np.mean(train_data['Age'])\ntrain_data.Age=train_data.Age.fillna(meanAge)"]}, {"cell_type": "code", "execution_count": 1, "id": "bef0d3d3", "metadata": {}, "outputs": [], "source": ["# Now for the cabin, since the majority of values are missing, it might be best to treat that\n# as a piece of information itself, so we\u2019ll set these to be \u2018Unknown\u2019\ntrain_data.Cabin = train_data.Cabin.fillna('Unknown')"]}, {"cell_type": "code", "execution_count": 1, "id": "ef14042e", "metadata": {}, "outputs": [], "source": ["# Fill embarked with the mean\ntrain_data.Embarked = train_data.Embarked.fillna(method=\"ffill\")"]}, {"cell_type": "code", "execution_count": 1, "id": "49e63379", "metadata": {}, "outputs": [], "source": ["train_data.isna().sum()\ntrain_data.isnull().sum()"]}, {"cell_type": "markdown", "id": "7e57426f", "metadata": {}, "source": ["All null values are gone. Let's see how that changes are stats."]}, {"cell_type": "code", "execution_count": 1, "id": "8cc2f9f1", "metadata": {}, "outputs": [], "source": ["train_data.describe()"]}, {"cell_type": "markdown", "id": "3b9999c5", "metadata": {}, "source": ["# EDA"]}, {"cell_type": "markdown", "id": "adbdced2", "metadata": {}, "source": ["There is a well known correlation between gender and survival. It is also in the titantic tutorial."]}, {"cell_type": "code", "execution_count": 1, "id": "03c2c253", "metadata": {}, "outputs": [], "source": ["women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\n\nprint(\"% of women who survived:\", rate_women)"]}, {"cell_type": "code", "execution_count": 1, "id": "dd7ed02c", "metadata": {}, "outputs": [], "source": ["men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)/len(men)\n\nprint(\"% of men who survived:\", rate_men)"]}, {"cell_type": "code", "execution_count": 1, "id": "1be9198a", "metadata": {}, "outputs": [], "source": ["# Let's do some more eda with plotting stuff\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ncorr = train_data.corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# the plotting\nsns.heatmap(corr, mask = mask, center = 0, cmap='cool',linewidths=1,annot=True,fmt=\".2f\")\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "8257b631", "metadata": {}, "outputs": [], "source": ["# just to see how many survived\nsns.countplot(x='Survived',data=train_data)"]}, {"cell_type": "code", "execution_count": 1, "id": "4783f17d", "metadata": {}, "outputs": [], "source": ["sns.pairplot(data=train_data,hue='Survived')"]}, {"cell_type": "code", "execution_count": 1, "id": "d4d9dc69", "metadata": {}, "outputs": [], "source": ["# see sex against survival\nsns.barplot(x='Sex',y='Survived',data=train_data)"]}, {"cell_type": "code", "execution_count": 1, "id": "0d0388a5", "metadata": {}, "outputs": [], "source": ["# see the number of people who survived or didn't against sex, class, and embarked from\nf, axes = plt.subplots(3,figsize=(9,15))\n#sns.set_style(\"darkgrid\")\nsns.countplot(x='Pclass',hue='Survived',data=train_data,ax=axes[0])\nsns.countplot(x='Sex',hue='Survived',data=train_data,ax=axes[1])\nsns.countplot(x='Embarked',hue='Survived',data=train_data,ax=axes[2])\nplt.show()"]}, {"cell_type": "code", "execution_count": 1, "id": "effb9812", "metadata": {}, "outputs": [], "source": ["# there is a lot of different cabins\n# we can probably reduce this\nprint(train_data['Cabin'].unique())"]}, {"cell_type": "code", "execution_count": 1, "id": "05dc4851", "metadata": {}, "outputs": [], "source": ["# this can probably be reduced as well\nprint(train_data['Ticket'].unique())"]}, {"cell_type": "code", "execution_count": 1, "id": "b4ce00b5", "metadata": {}, "outputs": [], "source": ["# this finds since sex is tied with survival so too is title\ntrain_data['name_title'] = train_data.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\ntrain_data['name_title'].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "ca268ee0", "metadata": {}, "outputs": [], "source": ["# already took of care of null values\ntrain_data['cabin_multiple'] = train_data.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split(' ')))\ntrain_data['cabin_multiple'].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "6def45bc", "metadata": {}, "outputs": [], "source": ["pd.pivot_table(train_data, index = 'Survived', columns = 'cabin_multiple', values = 'Ticket' ,aggfunc ='count')"]}, {"cell_type": "code", "execution_count": 1, "id": "79a49773", "metadata": {}, "outputs": [], "source": ["train_data['cabin_adv'] = train_data.Cabin.apply(lambda x: str(x)[0])\nprint(train_data.cabin_adv.value_counts())"]}, {"cell_type": "code", "execution_count": 1, "id": "4510d461", "metadata": {}, "outputs": [], "source": ["pd.pivot_table(train_data,index='Survived',columns='cabin_adv', values = 'Name', aggfunc='count')"]}, {"cell_type": "code", "execution_count": 1, "id": "7595cd63", "metadata": {}, "outputs": [], "source": ["#understand ticket values better \n#numeric vs non numeric \ntrain_data['numeric_ticket'] = train_data.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\ntrain_data['ticket_letters'] = train_data.Ticket.apply(lambda x: ''.join(x.split(' ')[:-1]).replace('.','').replace('/','').lower() if len(x.split(' ')[:-1]) >0 else 0)"]}, {"cell_type": "code", "execution_count": 1, "id": "47ae404e", "metadata": {}, "outputs": [], "source": ["train_data['numeric_ticket'].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "81eef043", "metadata": {}, "outputs": [], "source": ["pd.set_option(\"max_rows\", None)\ntrain_data['ticket_letters'].value_counts()"]}, {"cell_type": "code", "execution_count": 1, "id": "0f71b833", "metadata": {}, "outputs": [], "source": ["pd.pivot_table(train_data,index='Survived',columns='numeric_ticket', values = 'Ticket', aggfunc='count')"]}, {"cell_type": "code", "execution_count": 1, "id": "a54e85a3", "metadata": {}, "outputs": [], "source": ["pd.pivot_table(train_data,index='Survived',columns='ticket_letters', values = 'Ticket', aggfunc='count')"]}, {"cell_type": "markdown", "id": "154f2816", "metadata": {}, "source": ["# Models\nWe prepare the models for buliding then bulid them"]}, {"cell_type": "code", "execution_count": 1, "id": "5c1c324a", "metadata": {}, "outputs": [], "source": ["# dropping irrelvant features first\ntrain_reduced = train_data.drop([\"PassengerId\",\"Name\",\"Cabin\",\"Ticket\",\"ticket_letters\"],axis=1)\ntrain_reduced.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "523da688", "metadata": {}, "outputs": [], "source": ["train_reduced['Sex'] = pd.get_dummies(train_reduced.Sex, drop_first=True)"]}, {"cell_type": "code", "execution_count": 1, "id": "50a23c3a", "metadata": {}, "outputs": [], "source": ["# label encoder will be used for Embarked, name_title, and cabin_adv\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nlr = LabelEncoder()\ntrain_reduced['Embarked']= lr.fit_transform(train_reduced['Embarked'])\ntrain_reduced['name_title']= lr.fit_transform(train_reduced['name_title'])\ntrain_reduced['cabin_adv']= lr.fit_transform(train_reduced['cabin_adv'])\ntrain_reduced.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "7a29f108", "metadata": {}, "outputs": [], "source": ["y = train_reduced['Survived']\nX = train_reduced.drop(\"Survived\",axis=1)\n\nscaler = StandardScaler()\nX_std = scaler.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.30, random_state=0)"]}, {"cell_type": "code", "execution_count": 1, "id": "9d1fc69c", "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error as MSE\n\n# linear regression model\nline_reg = LinearRegression()\n#y_train_array = np.array(y_train)\n#y_train_reg = y_train_array.reshape(-1,1)\n#y_test_array = np.array(y_test)\n#y_test_reg = y_test_array.reshape(-1,1)\nline_reg.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "fc357eca", "metadata": {}, "outputs": [], "source": ["knn = KNN(n_neighbors=4)\nknn.fit(X_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "e1237973", "metadata": {}, "outputs": [], "source": ["dt = DecisionTreeClassifier(criterion='entropy',random_state=0)\ndt.fit(X_train,y_train)"]}, {"cell_type": "code", "execution_count": 1, "id": "2a1e7d03", "metadata": {}, "outputs": [], "source": ["sgd = SGDClassifier(random_state=0)\nsgd.fit(X_train,y_train)"]}, {"cell_type": "markdown", "id": "b3446df6", "metadata": {}, "source": ["# Evaluation\nWe will find the predictions of each model and get the accuracy score. The one with the best accuracy will be used."]}, {"cell_type": "code", "execution_count": 1, "id": "d6017fcb", "metadata": {}, "outputs": [], "source": ["pred_line_reg = line_reg.predict(X_test)\n#acc_line_reg = accuracy_score(y_test_reg, pred_line_reg)\n#acc_line_reg = line_reg.score(y_test, pred_line_reg)\n#acc_line_reg = line_reg.score(y_test,pred_line_reg)\n\n# can not evalute with accuracy score metric will used rmse instead\nrmse = np.sqrt(MSE(y_test,pred_line_reg))\nprint(rmse)"]}, {"cell_type": "code", "execution_count": 1, "id": "8f945033", "metadata": {}, "outputs": [], "source": ["pred_knn = knn.predict(X_test)\nacc_knn = accuracy_score(y_test, pred_knn)\nprint(acc_knn)"]}, {"cell_type": "code", "execution_count": 1, "id": "9f4d7232", "metadata": {}, "outputs": [], "source": ["pred_dt = dt.predict(X_test)\nacc_dt = accuracy_score(y_test, pred_dt)\nprint(acc_dt)"]}, {"cell_type": "code", "execution_count": 1, "id": "9b012e9f", "metadata": {}, "outputs": [], "source": ["pred_sgd = sgd.predict(X_test)\nacc_sgd = accuracy_score(y_test, pred_sgd)\nprint(acc_sgd)"]}, {"cell_type": "markdown", "id": "5e9c120d", "metadata": {}, "source": ["# Submission\nThe best model is knn. We will use that to generate the submission data."]}, {"cell_type": "code", "execution_count": 1, "id": "8882f3f8", "metadata": {}, "outputs": [], "source": ["print(len(test_data.columns))\nprint(test_data.columns)\ntest_data.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "680fcdff", "metadata": {}, "outputs": [], "source": ["# now we know what needs to be fixed\ntest_data.isna().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "16ed718a", "metadata": {}, "outputs": [], "source": ["meanAge=np.mean(test_data['Age'])\ntest_data.Age=test_data.Age.fillna(meanAge)\ntest_data.Cabin = test_data.Cabin.fillna('Unknown')\nmeanFare=np.mean(test_data['Fare'])\ntest_data.Fare=test_data.Age.fillna(meanFare)\ntest_data.isna().sum()"]}, {"cell_type": "code", "execution_count": 1, "id": "b4843864", "metadata": {}, "outputs": [], "source": ["# adding the features we engineered\ninbetween = test_data\ninbetween['name_title'] = inbetween.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\ninbetween['cabin_multiple'] = inbetween.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split(' ')))\ninbetween['cabin_adv'] = inbetween.Cabin.apply(lambda x: str(x)[0])\ninbetween['numeric_ticket'] = inbetween.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\ninbetween['ticket_letters'] = inbetween.Ticket.apply(lambda x: ''.join(x.split(' ')[:-1]).replace('.','').replace('/','').lower() if len(x.split(' ')[:-1]) >0 else 0)\ninbetween.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "0feb671b", "metadata": {}, "outputs": [], "source": ["id_col = test_data['PassengerId']\ninbetween['Sex'] = pd.get_dummies(inbetween.Sex, drop_first=True)\ninbetween['Embarked']= lr.fit_transform(inbetween['Embarked'])\ninbetween['name_title']= lr.fit_transform(inbetween['name_title'])\ninbetween['cabin_adv']= lr.fit_transform(inbetween['cabin_adv'])\ninbetween.head()"]}, {"cell_type": "code", "execution_count": 1, "id": "fb9b07c8", "metadata": {}, "outputs": [], "source": ["X_semifinal = test_data.drop([\"PassengerId\",\"Name\",\"Cabin\",\"Ticket\",\"ticket_letters\"],axis=1)\nX_final = scaler.fit_transform(X_semifinal)\n\n# error here\npredictions = knn.predict(X_final)\n\noutput = pd.DataFrame({'PassengerId': id_col, 'Survived': predictions})\noutput.head()\n\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}